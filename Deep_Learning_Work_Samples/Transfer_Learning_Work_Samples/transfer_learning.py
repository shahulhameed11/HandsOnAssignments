# -*- coding: utf-8 -*-
"""Transfer_Learning.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1CblkRuWNaT_Jvp3Hy8Ce4bfkli5l4Axz

# Transfer Learning to classify food/non food images using Tensorflow 2.0 (Google colab)

## Importing Tensorflow2.0
"""

# Commented out IPython magic to ensure Python compatibility.

try:
#   %tensorflow_version 2.x  # Colab only.
except Exception:
  pass

import tensorflow as tf
print(tf.__version__)

"""## Import necessary libraries, VGG16"""

from tensorflow.keras.layers import Input, Dense, Flatten
from tensorflow.keras.applications.vgg16 import VGG16 as PretrainedModel, \
  preprocess_input
from tensorflow.keras.models import Model
from tensorflow.keras.optimizers import SGD, Adam
from tensorflow.keras.preprocessing import image
from tensorflow.keras.preprocessing.image import ImageDataGenerator

from glob import glob

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import sys, os

"""## Download the dataset"""

!wget -nc https://lazyprogrammer.me/course_files/Food-5K.zip

"""## unzipping the data"""

!unzip -qq -o Food-5K.zip

!ls

!ls Food-5K/training

!mv Food-5K/* .

"""## sample image"""

plt.imshow(image.load_img('training/0_808.jpg'))
plt.show()

"""##  Food images start with 1, non-food images start with 0"""

plt.imshow(image.load_img('training/1_616.jpg'))
plt.show()

!mkdir data

"""## Make directories to store the data Keras-style

"""

!mkdir data/train
!mkdir data/test
!mkdir data/train/nonfood
!mkdir data/train/food
!mkdir data/test/nonfood
!mkdir data/test/food

"""## Move the images to respective folders

"""

!mv training/0*.jpg data/train/nonfood
!mv training/1*.jpg data/train/food
!mv validation/0*.jpg data/test/nonfood
!mv validation/1*.jpg data/test/food

train_path = 'data/train'
valid_path = 'data/test'

"""## Since images are huge defining the standard size for the training and testing"""

IMAGE_SIZE = [200, 200]

image_files = glob(train_path + '/*/*.jpg')
valid_image_files = glob(valid_path + '/*/*.jpg')

folders = glob(train_path + '/*')
folders

"""## sample non food image"""

plt.imshow(image.load_img(np.random.choice(image_files)))
plt.show()

"""## Loading the imagenet VGG weights  """

ptm = PretrainedModel(
    input_shape=IMAGE_SIZE + [3],
    weights='imagenet',
    include_top=False)

"""## freeze pretrained model weights

"""

ptm.trainable = False

"""## map the data into feature vectors, one hot encoding"""

K = len(folders) # number of classes
x = Flatten()(ptm.output)
x = Dense(K, activation='softmax')(x)

"""## create a model object"""

model = Model(inputs=ptm.input, outputs=x)

"""## view the structure of the model

"""

model.summary()

"""##  Data Augmentation for the images, creates additional samples"""

gen_train = ImageDataGenerator(
  rotation_range=20,
  width_shift_range=0.1,
  height_shift_range=0.1,
  shear_range=0.1,
  zoom_range=0.2,
  horizontal_flip=True,
  preprocessing_function=preprocess_input
)

gen_test = ImageDataGenerator(
  preprocessing_function=preprocess_input
)

batch_size = 128

train_generator = gen_train.flow_from_directory(
  train_path,
  shuffle=True,
  target_size=IMAGE_SIZE,
  batch_size=batch_size,
)
valid_generator = gen_test.flow_from_directory(
  valid_path,
  target_size=IMAGE_SIZE,
  batch_size=batch_size,
)

model.compile(
  loss='categorical_crossentropy',
  optimizer='adam',
  metrics=['accuracy']
)

"""## Fitting the model"""

r = model.fit_generator(
  train_generator,
  validation_data=valid_generator,
  epochs=5,
  steps_per_epoch=int(np.ceil(len(image_files) / batch_size)),
  validation_steps=int(np.ceil(len(valid_image_files) / batch_size)),
)

"""## Plotting Validation and Training loss """

plt.plot(r.history['loss'], label='train loss')
plt.plot(r.history['val_loss'], label='val loss')
plt.legend()
plt.show()

"""## Plotting Validation and Training accuracy """

plt.plot(r.history['accuracy'], label='train acc')
plt.plot(r.history['val_accuracy'], label='val acc')
plt.legend()
plt.show()

